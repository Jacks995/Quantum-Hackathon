{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Quantum 101\n",
    "    Important Links \n",
    "\n",
    "    * Installation (Docker recommended)\n",
    "        https://nvidia.github.io/cuda-quantum/latest/install.html \n",
    "    * Documentation\n",
    "        https://nvidia.github.io/cuda-quantum/latest/index.html\n",
    "    * CUDA Quantum Repo\n",
    "        https://github.com/NVIDIA/cuda-quantum\n",
    "    * Scaling Applications\n",
    "        https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html\n",
    "\n",
    "\n",
    "    Outline \n",
    "\n",
    "    1. What is CUDA Quantum? \n",
    "    2. CUDA Quantum Kernels\n",
    "    3. CUDA Quantum Primitives\n",
    "        3.1 cudaq.sample() \n",
    "        3.2 cudaq.spin_op()\n",
    "        3.3 cudaq.observe()\n",
    "    4. Parameterized circuits \n",
    "    5. Noise-modeling\n",
    "    6. Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CUDA Quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - NVIDIAâ€™s open-source platform for hybrid quantum-classical computing \n",
    "\n",
    "    - Built for high-performance, scalability, and ease-of-use\n",
    "\n",
    "    - As all valuable quantum applications of the future will be hybrid, CUDA Quantum enables users to develop performant hybrid applications that can easily scale to supercomputing scale.\n",
    "\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"doe_excerpts.png\" alt=\"Image Title\" width=\"600\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CUDA Quantum Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the CUDA Quantum module\n",
    "import cudaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We begin by defining the `Kernel` that we will construct our\n",
    "kernel = cudaq.make_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we can allocate qubits to the kernel via `qalloc(qubit_count)`.\n",
    "# An empty call to `qalloc` will return a single qubit.\n",
    "qubit = kernel.qalloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Now we can begin adding instructions to apply to this qubit!\n",
    "# Here we'll just add a selection of single qubit gates\n",
    "kernel.h(qubit)\n",
    "kernel.x(qubit)\n",
    "kernel.y(qubit)\n",
    "kernel.z(qubit)\n",
    "kernel.t(qubit)\n",
    "kernel.s(qubit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudaq._pycudaq.QuakeValue at 0x7fd6ff62d430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we add a measurement to the kernel so that we can sample\n",
    "# the measurement results on our simulator!\n",
    "kernel.mz(qubit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'adjoint',\n",
       " 'apply_call',\n",
       " 'argument_count',\n",
       " 'arguments',\n",
       " 'c_if',\n",
       " 'ch',\n",
       " 'control',\n",
       " 'cr1',\n",
       " 'crx',\n",
       " 'cry',\n",
       " 'crz',\n",
       " 'cs',\n",
       " 'cswap',\n",
       " 'ct',\n",
       " 'cx',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'exp_pauli',\n",
       " 'fermionic_swap',\n",
       " 'for_loop',\n",
       " 'givens_rotation',\n",
       " 'h',\n",
       " 'mx',\n",
       " 'my',\n",
       " 'mz',\n",
       " 'name',\n",
       " 'qalloc',\n",
       " 'r1',\n",
       " 'reset',\n",
       " 'rx',\n",
       " 'ry',\n",
       " 'rz',\n",
       " 's',\n",
       " 'sdg',\n",
       " 'swap',\n",
       " 't',\n",
       " 'tdg',\n",
       " 'to_quake',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other methods and attributes available to the kernel object\n",
    "dir(kernel)\n",
    "#help(kernel.tdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     3. Algorithmic primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Algorithmic primitives are common programming patterns that have \n",
    "  been implemented in the CUDA Quantum library.\n",
    "\n",
    "    3.1 cudaq.sample()\n",
    "    3.2 cudaq.observe()\n",
    "    3.3 cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. cudaq.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      The sample() function performs multiple measurements of the \n",
    "      circuit(1000 shots by default) and returns a dictionary of the\n",
    "      measurement outcomes along with their respective counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 0:519 1:481 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can execute this kernel on the state vector simulator\n",
    "# by calling `cudaq.sample`. This will execute the provided kernel\n",
    "# `shots_count` number of times and return the sampled distribution\n",
    "# as a `cudaq.SampleResult` dictionary.\n",
    "sample_result = cudaq.sample(kernel)\n",
    "\n",
    "# Now let's take a look at the `SampleResult` we've gotten back!\n",
    "print(sample_result)  # or result.dump()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 00:1007 11:993 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc(2)\n",
    "                                  \n",
    "kernel.h(qubit[0])\n",
    "kernel.cx(qubit[0], qubit[1])\n",
    "\n",
    "kernel.mz(qubit)\n",
    "\n",
    "sample_result = cudaq.sample(kernel, shots_count=2000) \n",
    "\n",
    "print(sample_result)  # or sample_result.dump() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most probable = 0\n",
      "count = 0\n",
      "probability = 0.0\n",
      "Marginal counts for qubit 0 = { 0:519 1:481 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting data from sample\n",
    "\n",
    "print(f\"most probable = {sample_result.most_probable()}\")\n",
    "print(f\"count for 11 = {sample_result.count('11')}\")\n",
    "print(f\"probability for 11 = {sample_result.probability('11')}\") # i.e. probability from sample\n",
    "print(f\"Marginal counts for qubit 0 = {sample_result.get_marginal_counts([0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clear results, result should now be empty\n",
    "sample_result.clear()\n",
    "print(sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2. cudaq.spin_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "    The spin_op represents a sum of Pauli tensor products. \n",
    "    \n",
    "    - Typical algebraic operations can be used to compose larger,\n",
    "    more complex Pauli tensor products and their sums. \n",
    "\n",
    "Let's take the Hamitonian H such that, H  = $Z_0 \\otimes I_1 + I_0 \\otimes X_1 + Y_0 \\otimes I_1 + Y_0 \\otimes Y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2+0j] IZZ\n",
      "[1+0j] ZII\n",
      "[1+0j] YII\n",
      "[1+0j] IXI\n",
      "[1+0j] YYI\n",
      "[-2+0j] ZZI\n",
      "\n",
      "(-3,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0) (-1,0)  (0,0)\n",
      " (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0) (-1,0)\n",
      " (1,0)  (0,0)  (5,0)  (0,0)  (1,0)  (0,0)  (0,1)  (0,0)\n",
      " (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (1,0)  (0,0)  (0,1)\n",
      "(0,-1)  (0,0)  (1,0)  (0,0) (-1,0)  (0,0)  (1,0)  (0,0)\n",
      " (0,0) (0,-1)  (0,0)  (1,0)  (0,0)  (3,0)  (0,0)  (1,0)\n",
      "(-1,0)  (0,0) (0,-1)  (0,0)  (1,0)  (0,0) (-1,0)  (0,0)\n",
      " (0,0) (-1,0)  (0,0) (0,-1)  (0,0)  (1,0)  (0,0) (-5,0)\n",
      "\n",
      "([(-3+0j), (1+0j), 1j, (-1+0j), (1+0j), (1+0j), 1j, (-1+0j), (1+0j), (5+0j), (1+0j), 1j, (1+0j), (1+0j), (1+0j), 1j, -1j, (1+0j), (-1+0j), (1+0j), -1j, (1+0j), (3+0j), (1+0j), (-1+0j), -1j, (1+0j), (-1+0j), (-1+0j), -1j, (1+0j), (-5+0j)], [0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7, 0, 2, 4, 6, 1, 3, 5, 7], [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Importing the spin_op\n",
    "from cudaq import spin\n",
    "\n",
    "# the obseravle \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# add some more terms\n",
    "for i in range(2):\n",
    "  hamiltonian += -2.0*spin.z(i)*spin.z(i+1)\n",
    "\n",
    "print(hamiltonian)\n",
    "print(hamiltonian.to_matrix())\n",
    "print(hamiltonian.to_sparse_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__rsub__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " 'distribute_terms',\n",
       " 'dump',\n",
       " 'for_each_pauli',\n",
       " 'for_each_term',\n",
       " 'from_word',\n",
       " 'get_coefficient',\n",
       " 'get_qubit_count',\n",
       " 'get_raw_data',\n",
       " 'get_term_count',\n",
       " 'is_identity',\n",
       " 'random',\n",
       " 'serialize',\n",
       " 'to_matrix',\n",
       " 'to_sparse_matrix',\n",
       " 'to_string']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. cudaq.observe()\n",
    "\n",
    "Compute the expected value of the observable, i.e., $\\bra{\\psi}H\\ket{\\psi}$, where $H$ is a cudaq spin_op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the observable \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0) + spin.y(0)*spin.y(1)\n",
    "\n",
    "# First we need to construct a cuda quantum kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "\n",
    "# The cudaq.observe() takes the quantum circuit and the observable as input params\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, shots_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{ \n",
      "  __global__ : { }\n",
      "   ZI : { 1:1000 }\n",
      "   YI : { 1:502 0:498 }\n",
      "   IX : { 1:500 0:500 }\n",
      "   YY : { 11:255 01:246 10:228 00:271 }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(observe_result.dump())\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'counts',\n",
       " 'dump',\n",
       " 'expectation',\n",
       " 'expectation_z',\n",
       " 'get_spin']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a complete list of attributes\n",
    "dir(observe_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parameterized circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7487943680728968"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# the observable \n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) \\\n",
    "            - 2.1433 * spin.y(0) * spin.y(1) + 0.21829 * spin.z(0) \\\n",
    "            - 6.125 * spin.z(1)\n",
    "\n",
    "# parameterized cudaq kernel, the parameter is of type float\n",
    "kernel, theta = cudaq.make_kernel(float)\n",
    "q = kernel.qalloc(2)\n",
    "kernel.x(q[0])\n",
    "kernel.ry(theta, q[1])\n",
    "kernel.cx(q[1], q[0])\n",
    "\n",
    "# observe() takes the kernel, the observable and the kernel parameters\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, .59)\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.283015765325521"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# the observable \n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) \\\n",
    "            - 2.1433 * spin.y(0) * spin.y(1) + 0.21829 * spin.z(0) \\\n",
    "            - 6.125 * spin.z(1)\n",
    "\n",
    "# parameterized cudaq kernel, the parameter is of type float\n",
    "kernel, theta = cudaq.make_kernel(list)\n",
    "q = kernel.qalloc(2)\n",
    "kernel.x(q[0])\n",
    "kernel.ry(theta[0], q[1])\n",
    "kernel.ry(theta[1], q[1])\n",
    "kernel.cx(q[1], q[0])\n",
    "\n",
    "# observe() takes the kernel, the observable and the kernel parameters\n",
    "observe_result = cudaq.observe(kernel, hamiltonian, [.59, .75])\n",
    "observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Noise modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Noise can be represnted mathematically using the Kraus operators.\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\rho \\mapsto {\\cal{N}}(\\rho) = \\sum_{j} K_j \\rho K_j^{\\dag}\n",
    "\\end{equation*}\n",
    "\n",
    "    with the condition that \n",
    "    \n",
    "\\begin{equation*}\n",
    "\\sum_{j} K_j K_j^{\\dag} = \\mathbb{I}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A single-qubit bit-flip error can be expressed as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\rho = (1-p) \\rho + p X\\rho X \n",
    "\\end{equation*}\n",
    "    with p in [0,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 0:108 1:892 }\n",
      "{ 1:1000 }\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# these decoherence channels to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# Bit flip channel with `1.0` probability of the qubit flipping 180 degrees.\n",
    "bit_flip = cudaq.BitFlipChannel(.1)\n",
    "# We will apply this channel to any X gate on the qubit, giving each X-gate\n",
    "# a probability of `1.0` of undergoing an extra X-gate.\n",
    "noise.add_channel('x', [0], bit_flip)\n",
    "\n",
    "# construct a circuit\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "\n",
    "# Apply an X-gate to the qubit.\n",
    "# It will remain in the |1> state with a probability of `1 - p = 0.9`.\n",
    "kernel.x(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy simulation\n",
    "\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless simulation\n",
    "\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Custom Noise Model\n",
    "\n",
    "     Here, we demonstrate a custom noise model with the same Kraus operators as in the ampltiude damping channel, but following the same template we can build other noise models such as the Pauli noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 0:1000 }\n",
      "{ 0:477 1:523 }\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# Set the target to our density matrix simulator.\n",
    "cudaq.set_target('density-matrix-cpu')\n",
    "\n",
    "# We will begin by defining an empty noise model that we will add\n",
    "# our Kraus Channel to.\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "# We will define our Kraus Operators within functions, as to\n",
    "# allow for easy control over the noise probability.\n",
    "def kraus_operators(probability):\n",
    "    \"\"\"See Nielsen, Chuang Chapter 8.3.5 for definition source.\"\"\"\n",
    "    kraus_0 = np.array([[1, 0], [0, np.sqrt(1 - probability)]],\n",
    "                       dtype=np.complex128)\n",
    "    kraus_1 = np.array([[0, 0], [np.sqrt(probability), 0]], dtype=np.complex128)\n",
    "    return [kraus_0, kraus_1]\n",
    "\n",
    "\n",
    "# Manually defined amplitude damping channel with `1.0` probability\n",
    "# of the qubit decaying to the ground state.\n",
    "amplitude_damping = cudaq.KrausChannel(kraus_operators(1.0))\n",
    "# We will apply this channel to any Hadamard gate on the qubit.\n",
    "noise.add_channel('h', [0], amplitude_damping)\n",
    "\n",
    "# construct a simple kernel\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.h(qubit)\n",
    "kernel.mz(qubit)\n",
    "\n",
    "# noisy\n",
    "noisy_result = cudaq.sample(kernel, noise_model=noise)\n",
    "noisy_result.dump()\n",
    "\n",
    "# noiseless\n",
    "noiseless_result = cudaq.sample(kernel)\n",
    "noiseless_result.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling applications in CUDA Quantum\n",
    "Main reference: https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets\n",
    "\n",
    "    - A combination of quantum circuit simulators and hardware.\n",
    "    - Allows you to switch between QPUs, CPUs and GPUs.\n",
    "    - The default target provides a state vector simulator run on a single NVIDIA GPU\n",
    "\n",
    "\n",
    "Available TargetsÂ¶\n",
    "\n",
    "        default (\"nvidia\") : GPU based backend which accelerates quantum circuit simulation on NVIDIA GPUs powered by cuQuantum, falls back on multithreaded CPU if no GPU availible.\n",
    "\n",
    "        nvidia-mqpu: Enables users to program workflows utilizing multiple quantum processors enabled today by GPU emulation.\n",
    "\n",
    "        nvidia-mgpu: Allows for scaling circuit simulation beyond what is feasible with any QPU today.\n",
    "\n",
    "        density-matrix-cpu: Noisy simulations via density matrix calculations. CPU only for now with GPU support coming soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target nvidia-mgpu\n",
      "\tsimulator=nvidia_mgpu\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target tensornet\n",
      "\tsimulator=tensornet\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target density-matrix-cpu\n",
      "\tsimulator=dm\n",
      "\tplatform=default\n",
      "\tdescription=The Density Matrix CPU Target provides a simulated QPU via OpenMP-enabled, CPU-only density matrix emulation.\n",
      "\n",
      "Target iqm\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target photonics\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target quantinuum\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target orca\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA Target provides a simulated QPU via single-GPU cuStateVec integration on FP32 types.\n",
      "\n",
      "Target nvidia-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA FP64 Target provides a simulated QPU via single-GPU cuStateVec integration on FP64 types.\n",
      "\n",
      "Target nvidia-mqpu\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP32. This target enables asynchronous parallel execution of quantum kernel tasks.\n",
      "\n",
      "Target qpp-cpu\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=QPP-based CPU-only backend target\n",
      "\n",
      "Target oqc\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target ionq\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia-mqpu-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU FP64 Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP64.\n",
      "\n",
      "Target tensornet-mps\n",
      "\tsimulator=tensornet_mps\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print all the availble targets for your system\n",
    "import cudaq\n",
    "\n",
    "targets = cudaq.get_targets()\n",
    "\n",
    "for target in targets:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Some  ways to scale your application:\n",
    "  \n",
    "    1. Increasing the number of qubits (weak scaling)\n",
    "    \n",
    "            - mgpu backend\n",
    "    \n",
    "    2. Distributing the circuit execution (strong scaling)\n",
    "            2.1 asynchronous sampling\n",
    "            2.2 Hamiltonian batching\n",
    "            2.3 Parameter batching\n",
    "\n",
    "            - mqpu backend\n",
    "            - Each gpu acts as a virtual qpu\n",
    "\n",
    "         As a rule of thumb, we can parallelize over any of the input parameters to `cudaq.sample()` or `cudaq.observe()` - kernel, hamiltonian, kernel parameters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple NVIDIA GPUs for the mgpu backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The increase in qubit count leads to an exponential increase in the size of the statevector.\n",
    "    \n",
    "    - The nvidia-mgpu target allows for scaling the qubit count by pooling memory from GPUs across multiple nodes.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            \n",
    "                            GHZ state prep on ABCI\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"qubit_scaling.png\" alt=\"Image Title\" width=\"200\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous sampling via mqpu backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 4\n",
      "{ 00:518 11:482 }\n",
      "\n",
      "{ 00:507 11:493 }\n",
      "\n",
      "{ 00:490 11:510 }\n",
      "\n",
      "{ 00:473 11:527 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq \n",
    "\n",
    "#Set the target\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "target = cudaq.get_target()\n",
    "num_qpus = target.num_qpus()\n",
    "print(\"Number of QPUs:\", num_qpus)\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(2)\n",
    "kernel.h(qubits[0])\n",
    "kernel.cx(qubits[0], qubits[1])\n",
    "kernel.mz(qubits)\n",
    "\n",
    "futures = []\n",
    "for i in range(num_qpus):\n",
    "  futures.append(cudaq.sample_async(kernel, qpu_id=i))\n",
    "  \n",
    "\n",
    "for count in futures:\n",
    "    print(count.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Asynchronous expectation value computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measuring in the Z-basis.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Call `cudaq.observe()` at the specified number of shots.\n",
    "future = cudaq.observe_async(kernel=kernel,\n",
    "                            spin_operator=hamiltonian,\n",
    "                            qpu_id=0,\n",
    "                            shots_count=2000)\n",
    "observe_result = future.get()\n",
    "got_expectation = observe_result.expectation()\n",
    "print(got_expectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Hamiltonian term distribution over multiple QPUs\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"hamiltonian_batch.png\" alt=\"Image Title\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.355104993498015e-09"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudaq\n",
    "\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "\n",
    "qubit_count = 16\n",
    "term_count = 100\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(qubit_count)\n",
    "kernel.h(qubits[0])\n",
    "\n",
    "for i in range(1, qubit_count):\n",
    "    kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "# We create a random hamiltonian with several terms\n",
    "hamiltonian = cudaq.SpinOperator.random(qubit_count, term_count)\n",
    "\n",
    "# The observe calls allows us to calculate the expectation value of the Hamiltonian,\n",
    "# batches the terms, and distributes them over the multiple QPU's/GPUs.\n",
    "# expectation = cudaq.observe(kernel, hamiltonian)  # Single node, single GPU.\n",
    "\n",
    "expectation = cudaq.observe(kernel, hamiltonian, \n",
    "                        execution=cudaq.parallel.thread)  # Single node, multi-GPU.\n",
    "\n",
    "#expectation = cudaq.observe(kernel, hamiltonian, \n",
    "#                      execution= cudaq.parallel.mpi) # Multi-node, multi-GPU.\n",
    "\n",
    "expectation.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    More on workflows enabled by the use of multiple gpus:\n",
    "https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Physical QPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cudaq.set_target('quantinuum')\n",
    "#cudaq.set_target('quantinuum', machine='H1-2')\n",
    "#cudaq.sample(kernel, shots_count=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Adjoing of a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq \n",
    "\n",
    "# Create a kernel and do some operations\n",
    "other_kernel = cudaq.make_kernel()\n",
    "other_qubit = other_kernel.qalloc()\n",
    "other_kernel.x(other_qubit)\n",
    "\n",
    "# Create a kernel, which'll be the adjoint of other_kernel \n",
    "kernel = cudaq.make_kernel()\n",
    "kernel.adjoint(other_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conditional Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "  __global__ : { 0:30 }\n",
      "   auto_register_0 : { 1:30 }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " # The conditional measurement functionality of `cudaq.kernel`\n",
    "import cudaq \n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "\n",
    "def then_function():\n",
    "    kernel.x(qubit)\n",
    "\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measure the qubit.\n",
    "measurement_ = kernel.mz(qubit)\n",
    "# Apply `then_function` to the `kernel` if\n",
    "# the qubit was measured in the 1-state.\n",
    "kernel.c_if(measurement_, then_function)\n",
    "\n",
    "# Measure the qubit again.\n",
    "result = cudaq.sample(kernel, shots_count=30)\n",
    "result.dump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Algorithms\n",
    "\n",
    "    Variational algorithms in CUDA Quantum typically leverage the `cudaq.observe(...)` function in tandem with the `cudaq.optimizer`.\n",
    "\n",
    "    One can choose an optimization strategy provided as specific sub-types of the `cudaq.optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.999999761581421 [0.0]\n",
      "5.960464499743523e-08 [1.5707963267948966]\n",
      "-1.9999997019767757 [-1.5707963267948963]\n",
      "-0.9999996125698125 [-3.141592653589793]\n",
      "-0.999999761581421 [2.220446049250313e-16]\n",
      "-1.707106605172157 [-0.7853981633974481]\n",
      "-1.9238792918622494 [-1.9634954084936205]\n",
      "-1.9807852329686284 [-1.3744467859455343]\n",
      "-1.9951846345793456 [-1.6689710972195773]\n",
      "-1.9987954242387787 [-1.5217089415825558]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# Parameterized circuit with theta as the parameter\n",
    "kernel, theta = cudaq.make_kernel(list)\n",
    "qreg = kernel.qalloc(2)\n",
    "kernel.x(qreg[0])\n",
    "kernel.ry(theta[0], qreg[1])\n",
    "\n",
    "# Observable  \n",
    "hamiltonian = spin.z(0) + spin.x(1) + spin.y(0)  \n",
    "\n",
    "# Initialize the gradient-free optimizer COBYLA\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "\n",
    "# Specify the number of iterations (optional)\n",
    "optimizer.max_iterations = 10\n",
    "\n",
    "def cost_function(x):\n",
    "    # cudaq.observe() produces the expected value of a specified observable wrt a given parameterized ansatz at given params.\n",
    "    # This value is the cost function wrt which we are optimizing.\n",
    "    observeResult = cudaq.observe(kernel, hamiltonian, x)\n",
    "    print (observeResult.expectation(), x)\n",
    "    return observeResult.expectation()\n",
    "\n",
    "# Carry out the optimization\n",
    "opt_value, opt_theta = optimizer.optimize(dimensions=1, function=cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    VQE wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "minimized <H> = -0.9999999403953552\n",
      "optimal theta = 0.0\n"
     ]
    }
   ],
   "source": [
    " # Import the necessary modules\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "# Parameterized circuit with theta as the parameter\n",
    "kernel, theta = cudaq.make_kernel(list)\n",
    "qreg = kernel.qalloc(1)\n",
    "kernel.x(qreg[0])\n",
    "kernel.ry(theta[0], qreg[0])\n",
    "\n",
    "# Hamiltonian operator \n",
    "hamiltonian = hamiltonian = spin.z(0) \n",
    "\n",
    "\n",
    "# Initialize the gradient-free optimizer COBYLA\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "\n",
    "# Specify the number of iterations (optional)\n",
    "optimizer.max_iterations = 5\n",
    "\n",
    "# Carry out the optimization\n",
    "opt_value, opt_theta = cudaq.vqe(kernel=kernel, \n",
    "                        spin_operator=hamiltonian,\n",
    "                        optimizer=optimizer,\n",
    "                        parameter_count=1)\n",
    "\n",
    "print(f\"\\nminimized <H> = {round(opt_value,16)}\")\n",
    "print(f\"optimal theta = {round(opt_theta[0],16)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
